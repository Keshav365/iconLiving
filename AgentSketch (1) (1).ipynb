{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0DIPMa0-zZ0u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Error parsing dependencies of send2trash: Expected matching RIGHT_PARENTHESIS for LEFT_PARENTHESIS, after version specifier\n",
      "    sys-platform (==\"darwin\") ; extra == 'objc'\n",
      "                 ~^\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "huggingface-hub 0.27.0 requires fsspec>=2023.5.0, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Error parsing dependencies of send2trash: Expected matching RIGHT_PARENTHESIS for LEFT_PARENTHESIS, after version specifier\n",
      "    sys-platform (==\"darwin\") ; extra == 'objc'\n",
      "                 ~^\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "easyocr 1.7.2 requires torchvision>=0.5, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Error parsing dependencies of send2trash: Expected matching RIGHT_PARENTHESIS for LEFT_PARENTHESIS, after version specifier\n",
      "    sys-platform (==\"darwin\") ; extra == 'objc'\n",
      "                 ~^\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Error parsing dependencies of send2trash: Expected matching RIGHT_PARENTHESIS for LEFT_PARENTHESIS, after version specifier\n",
      "    sys-platform (==\"darwin\") ; extra == 'objc'\n",
      "                 ~^\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install -q streamlit\n",
    "!pip install -q torch\n",
    "!pip install -q transformers\n",
    "!pip install -q pyngrok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W6KweNXz4gcY",
    "outputId": "38544dab-fc14-4765-9480-97f083e7bc39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/diffusers\n",
      "  Cloning https://github.com/huggingface/diffusers to /tmp/pip-req-build-nw_5_iqe\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/diffusers /tmp/pip-req-build-nw_5_iqe\n",
      "  Resolved https://github.com/huggingface/diffusers to commit aad69ac2f323734a083d66fa89197bf7d88e5a57\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from diffusers==0.33.0.dev0) (8.6.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers==0.33.0.dev0) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.33.0.dev0) (0.27.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from diffusers==0.33.0.dev0) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.33.0.dev0) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers==0.33.0.dev0) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.33.0.dev0) (0.5.2)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers==0.33.0.dev0) (11.1.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers==0.33.0.dev0) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers==0.33.0.dev0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers==0.33.0.dev0) (6.0.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers==0.33.0.dev0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers==0.33.0.dev0) (4.12.2)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->diffusers==0.33.0.dev0) (3.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.33.0.dev0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.33.0.dev0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.33.0.dev0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.33.0.dev0) (2024.12.14)\n"
     ]
    }
   ],
   "source": [
    "! pip install git+https://github.com/huggingface/diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1poT-rd21Dq9",
    "outputId": "1cfac4c1-be7f-4b5f-fbab-2115eb5bc895"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.27.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2024.12.14)\n",
      "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.1)\n",
      "Requirement already satisfied: torch~=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.5.1+cu124)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch~=2.0->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch~=2.0->bitsandbytes) (3.0.2)\n",
      "Requirement already satisfied: xformers in /usr/local/lib/python3.11/dist-packages (0.0.29.post1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xformers) (1.26.4)\n",
      "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.11/dist-packages (from xformers) (2.5.1+cu124)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.5.1->xformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.5.1->xformers) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install huggingface_hub\n",
    "! pip install bitsandbytes\n",
    "!pip install xformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3PGjTnyf07xb"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Q9aN1wyb1An8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wPt0BQIez1iQ",
    "outputId": "88ad7ab5-6525-42eb-ef48-521d905f82b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import io\n",
    "import platform\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Page config\n",
    "st.set_page_config(\n",
    "    page_title=\"Text to Image Generator\",\n",
    "    page_icon=\"🎨\",\n",
    "    layout=\"wide\"\n",
    ")\n",
    "\n",
    "# Custom CSS to improve the interface\n",
    "st.markdown(\"\"\"\n",
    "    <style>\n",
    "        .stTextInput > label {\n",
    "            font-size: 20px;\n",
    "            font-weight: bold;\n",
    "        }\n",
    "        .stButton > button {\n",
    "            width: 100%;\n",
    "            height: 50px;\n",
    "            font-size: 18px;\n",
    "        }\n",
    "        .suggestion-button {\n",
    "            margin: 5px;\n",
    "            padding: 10px;\n",
    "        }\n",
    "    </style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# Define constants\n",
    "MODEL_ID = \"OFA-Sys/small-stable-diffusion-v0/\"\n",
    "MODEL_DIR = Path.home() / \".stable_diffusion_models\"\n",
    "\n",
    "# Define suggested prompts\n",
    "SUGGESTED_PROMPTS = {\n",
    "    \"Fantasy\": [\n",
    "        \"A magical crystal castle floating in the clouds with rainbow bridges\",\n",
    "        \"A wise ancient dragon reading books in a mystical library\",\n",
    "        \"A enchanted forest with glowing mushrooms and fairy lights\"\n",
    "    ],\n",
    "    \"Landscapes\": [\n",
    "        \"A serene mountain lake at sunset with snow-capped peaks\",\n",
    "        \"Rolling hills of lavender fields under a starry night sky\",\n",
    "        \"A tropical beach paradise with crystal clear waters and palm trees\"\n",
    "    ],\n",
    "    \"Abstract\": [\n",
    "        \"A surreal fusion of geometric shapes and flowing liquid colors\",\n",
    "        \"An abstract representation of music using swirling colors and light\",\n",
    "        \"A dream-like composition of floating objects and nebulous forms\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "def check_system_compatibility():\n",
    "    \"\"\"Check system compatibility and requirements\"\"\"\n",
    "    system_info = {\n",
    "        \"Python Version\": platform.python_version(),\n",
    "        \"PyTorch Version\": torch.__version__,\n",
    "        \"CUDA Available\": torch.cuda.is_available(),\n",
    "        \"System Platform\": platform.system(),\n",
    "        \"Model Directory\": str(MODEL_DIR),\n",
    "    }\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        system_info[\"CUDA Version\"] = torch.version.cuda\n",
    "        system_info[\"GPU Device\"] = torch.cuda.get_device_name(0)\n",
    "\n",
    "    return system_info\n",
    "\n",
    "def is_model_downloaded():\n",
    "    \"\"\"Check if the model is already downloaded\"\"\"\n",
    "    return (MODEL_DIR / \"model_index.json\").exists()\n",
    "\n",
    "def download_model():\n",
    "    \"\"\"Download the model to local storage\"\"\"\n",
    "    try:\n",
    "        logger.info(f\"Downloading model to {MODEL_DIR}\")\n",
    "        MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        pipe = StableDiffusionPipeline.from_pretrained(\n",
    "            MODEL_ID,\n",
    "            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "            safety_checker=None\n",
    "        )\n",
    "\n",
    "        pipe.save_pretrained(str(MODEL_DIR))\n",
    "        logger.info(\"Model downloaded successfully\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error downloading model: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "@st.cache_resource\n",
    "def load_model():\n",
    "    \"\"\"Load the model from local storage or download if necessary\"\"\"\n",
    "    try:\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        model_path = str(MODEL_DIR) if is_model_downloaded() else MODEL_ID\n",
    "\n",
    "        logger.info(f\"Loading model from {model_path} on {device}\")\n",
    "\n",
    "        pipe = StableDiffusionPipeline.from_pretrained(\n",
    "            model_path,\n",
    "            torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "            safety_checker=None\n",
    "        )\n",
    "\n",
    "        pipe = pipe.to(device)\n",
    "\n",
    "        if hasattr(pipe, 'enable_attention_slicing'):\n",
    "            pipe.enable_attention_slicing()\n",
    "\n",
    "        logger.info(\"Model loaded successfully\")\n",
    "        return pipe\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading model: {str(e)}\")\n",
    "        raise Exception(f\"Failed to load the model: {str(e)}\")\n",
    "\n",
    "def generate_image(prompt, num_inference_steps=50, guidance_scale=7.5):\n",
    "    \"\"\"Generate image from text prompt\"\"\"\n",
    "    try:\n",
    "        pipe = load_model()\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        with torch.autocast(device):\n",
    "            image = pipe(\n",
    "                prompt,\n",
    "                num_inference_steps=num_inference_steps,\n",
    "                guidance_scale=guidance_scale,\n",
    "            ).images[0]\n",
    "\n",
    "        return image\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error generating image: {str(e)}\")\n",
    "        raise Exception(f\"Failed to generate image: {str(e)}\")\n",
    "\n",
    "def display_suggested_prompts():\n",
    "    \"\"\"Display suggested prompts organized by category\"\"\"\n",
    "    st.subheader(\"✨ Suggested Prompts\")\n",
    "    st.write(\"Click on any prompt to use it!\")\n",
    "\n",
    "    tabs = st.tabs(list(SUGGESTED_PROMPTS.keys()))\n",
    "\n",
    "    for tab, (category, prompts) in zip(tabs, SUGGESTED_PROMPTS.items()):\n",
    "        with tab:\n",
    "            for prompt in prompts:\n",
    "                if st.button(prompt, key=f\"btn_{prompt}\", use_container_width=True):\n",
    "                    return prompt\n",
    "    return None\n",
    "\n",
    "def main():\n",
    "    st.title(\"🎨 Text to Image Generator\")\n",
    "\n",
    "    # Display system information in an expander\n",
    "    with st.expander(\"System Information\"):\n",
    "        system_info = check_system_compatibility()\n",
    "        for key, value in system_info.items():\n",
    "            st.write(f\"**{key}:** {value}\")\n",
    "\n",
    "    # Model download section\n",
    "    st.subheader(\"Model Management\")\n",
    "    col1, col2 = st.columns([1, 2])\n",
    "\n",
    "    with col1:\n",
    "        if is_model_downloaded():\n",
    "            st.success(\"✅ Model is downloaded locally\")\n",
    "        else:\n",
    "            st.warning(\"⚠️ Model not downloaded\")\n",
    "\n",
    "        if st.button(\"Download Model Locally\"):\n",
    "            with st.spinner(\"📥 Downloading model... This may take several minutes...\"):\n",
    "                if download_model():\n",
    "                    st.success(\"✅ Model downloaded successfully!\")\n",
    "                    st.rerun()  # Refresh the page to update the model status\n",
    "                else:\n",
    "                    st.error(\"❌ Failed to download model\")\n",
    "\n",
    "    with col2:\n",
    "        st.info(\n",
    "            \"Downloading the model locally will improve generation speed and allow offline use. \"\n",
    "            f\"The model will be stored in: {MODEL_DIR}\"\n",
    "        )\n",
    "\n",
    "    st.write(\"---\")\n",
    "\n",
    "    # Add suggested prompts section\n",
    "    selected_prompt = display_suggested_prompts()\n",
    "\n",
    "    st.write(\"---\")\n",
    "    st.write(\"Enter your prompt below or use one of the suggested prompts above!\")\n",
    "\n",
    "    # Text input for the prompt\n",
    "    prompt = st.text_area(\n",
    "        \"Enter your prompt:\",\n",
    "        value=selected_prompt if selected_prompt else \"\",\n",
    "        height=100,\n",
    "        placeholder=\"A serene landscape with mountains and a lake at sunset...\"\n",
    "    )\n",
    "\n",
    "    # Advanced options in an expander\n",
    "    with st.expander(\"Advanced Options\"):\n",
    "        col1, col2 = st.columns(2)\n",
    "        with col1:\n",
    "            num_steps = st.slider(\n",
    "                \"Number of inference steps\",\n",
    "                min_value=20,\n",
    "                max_value=100,\n",
    "                value=50,\n",
    "                help=\"Higher values = better quality but slower generation\"\n",
    "            )\n",
    "        with col2:\n",
    "            guidance = st.slider(\n",
    "                \"Guidance scale\",\n",
    "                min_value=1.0,\n",
    "                max_value=20.0,\n",
    "                value=7.5,\n",
    "                step=0.5,\n",
    "                help=\"How closely to follow the prompt. Higher values = more literal interpretation\"\n",
    "            )\n",
    "\n",
    "    # Generate button\n",
    "    if st.button(\"Generate Image\") or selected_prompt:\n",
    "        if not prompt:\n",
    "            st.error(\"Please enter a prompt first!\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            with st.spinner(\"🎨 Generating your image... This might take a minute...\"):\n",
    "                image = generate_image(prompt, num_steps, guidance)\n",
    "\n",
    "                # Display the generated image\n",
    "                st.success(\"✨ Image generated successfully!\")\n",
    "                st.image(image, caption=prompt, width=400)\n",
    "\n",
    "                # Add download button\n",
    "                buf = io.BytesIO()\n",
    "                image.save(buf, format=\"PNG\")\n",
    "                st.download_button(\n",
    "                    label=\"Download Image\",\n",
    "                    data=buf.getvalue(),\n",
    "                    file_name=\"generated_image.png\",\n",
    "                    mime=\"image/png\"\n",
    "                )\n",
    "\n",
    "        except Exception as e:\n",
    "            st.error(\"⚠️ Generation Error\")\n",
    "            st.error(str(e))\n",
    "            st.info(\"Try the following troubleshooting steps:\\n\"\n",
    "                   \"1. Check your internet connection\\n\"\n",
    "                   \"2. Verify that all dependencies are correctly installed\\n\"\n",
    "                   \"3. Try a different prompt\\n\"\n",
    "                   \"4. Reduce the number of inference steps\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QgSv0oCi2bmx",
    "outputId": "33f2548f-b2eb-4a93-bc80-deb03c96eda8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nohup: appending output to 'nohup.out'\n",
      " * Tunnel URL: https://f938-34-82-44-240.ngrok-free.app\n"
     ]
    }
   ],
   "source": [
    "from pyngrok import ngrok\n",
    "\n",
    "# Set authentication token if you haven't already done so\n",
    "ngrok.set_auth_token(\"2sLUuTzXl5fi3F3gyZJ9TmE4HUx_nLDPWkSpJnjy9LpBVvKM\")\n",
    "\n",
    "# Start Streamlit server on a specific port\n",
    "!nohup streamlit run app.py --server.port 5011 &\n",
    "\n",
    "# Start ngrok tunnel to expose the Streamlit server\n",
    "ngrok_tunnel = ngrok.connect(addr='5011', proto='http', bind_tls=True)\n",
    "\n",
    "# Print the URL of the ngrok tunnel\n",
    "print(' * Tunnel URL:', ngrok_tunnel.public_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "udCfA27RZ2uA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
